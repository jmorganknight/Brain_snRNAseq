{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This pipeline processes the mouse brain snRNAseq by selecting the microglia barcodes, mapped human orthologs, log normalized, integrated, concatenated, and metadata updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import os\n",
    "import time\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scvi\n",
    "import anndata as ad\n",
    "import torch\n",
    "import scanorama\n",
    "import copy\n",
    "import scvelo as scv\n",
    "import numba\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from mousipy import translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Set working directory for aggregated wt mice\n",
    "os.chdir('/media/drive_c/Project_Brain_snRNAseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Creating a df of the samples and the path to their filtered matrix.h5 files \n",
    "# Define the root directory where your sample folders are located\n",
    "root_dir = \"/media/drive_c/Project_Brain_snRNAseq/per_sample_outs\"\n",
    "\n",
    "# Initialize an empty list to store sample names and file paths\n",
    "data = []\n",
    "\n",
    "# Loop through each subfolder in the root directory\n",
    "for sample_folder in os.listdir(root_dir):\n",
    "    sample_path = os.path.join(root_dir, sample_folder, 'count', 'sample_filtered_feature_bc_matrix.h5')\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(sample_path):\n",
    "        # Append sample name and file path to the list\n",
    "        data.append({'Sample': sample_folder, 'Path': sample_path})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microglia Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of microglia barcodes from the CSV file\n",
    "\n",
    "barcode_file = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Microglia_analysis/microglia_cell_barcodes.csv\"\n",
    "barcodes_to_keep = pd.read_csv(barcode_file, header=None).squeeze().tolist()\n",
    "barcodes_to_keep = set(barcodes_to_keep)  # Convert to set for faster lookup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\n",
    "\n",
    "The ingest loops through a list of mouse single-cell datasets \n",
    "    - filters cells by barcode\n",
    "    - translates mouse genes to human orthologs\n",
    "    - normalizes and log-transforms the data\n",
    "    - stores each processed dataset in a dictionary\n",
    "    - also saves the mouseâ€“human gene map to CSV for later use...\n",
    "\n",
    "\"\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "# Dictionary to store processed AnnData objects\n",
    "filtered_adata_dict = {}\n",
    "\n",
    "# DataFrame to store unique mouse-human ortholog mappings\n",
    "df_ortholog = pd.DataFrame(columns=[\"Human_Gene\", \"Mouse_Gene\"])\n",
    "\n",
    "# Loop through each row in the input DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    sample_name = row[\"Sample\"]\n",
    "    file_path = row[\"Path\"]\n",
    "\n",
    "    # Load data\n",
    "    adata = sc.read_10x_h5(file_path, genome=None, gex_only=True)\n",
    "\n",
    "    # Subset to valid barcodes\n",
    "    filtered_adata = adata[adata.obs.index.isin(barcodes_to_keep)].copy()\n",
    "\n",
    "    # Ensure unique gene names\n",
    "    if filtered_adata.var_names.duplicated().any():\n",
    "        filtered_adata.var_names_make_unique()\n",
    "\n",
    "    # Translate mouse gene names to human\n",
    "    humanized_adata = translate(filtered_adata)\n",
    "\n",
    "    # Extract ortholog mapping\n",
    "    ortholog_map = humanized_adata.var[[\"original_gene_symbol\"]].reset_index()\n",
    "    ortholog_map.columns = [\"Human_Gene\", \"Mouse_Gene\"]\n",
    "    df_ortholog = pd.concat([df_ortholog, ortholog_map]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Drop genes without valid names\n",
    "    humanized_adata = humanized_adata[:, humanized_adata.var_names.notna()].copy()\n",
    "    humanized_adata.var_names = humanized_adata.var_names.astype(str)\n",
    "\n",
    "    # Store gene names in 'features' column\n",
    "    humanized_adata.var['features'] = humanized_adata.var['original_gene_symbol'].copy()\n",
    "    humanized_adata.var = humanized_adata.var[['features']]\n",
    "\n",
    "    if humanized_adata.n_obs > 0:\n",
    "        # Drop all columns from .obs and add metadata\n",
    "        humanized_adata.obs = pd.DataFrame(index=humanized_adata.obs.index)\n",
    "        humanized_adata.obs[\"Sample\"] = sample_name\n",
    "        humanized_adata.obs[\"Study_Designation\"] = \"Naive\" if \"Mock\" in sample_name else \"Infected\"\n",
    "        humanized_adata.obs[\"Dataset\"] = \"mouse\"\n",
    "\n",
    "        # Save raw before normalization\n",
    "        humanized_adata.raw = humanized_adata.copy()\n",
    "\n",
    "        # Normalize, log-transform\n",
    "        sc.pp.normalize_total(humanized_adata, target_sum=1e4)\n",
    "        sc.pp.log1p(humanized_adata)\n",
    "\n",
    "        # Optional scaling (commented out, better to scale after merged/concatenated)\n",
    "        #sc.pp.scale(humanized_adata, zero_center=True, max_value=10)\n",
    "\n",
    "        # Store in dictionary\n",
    "        filtered_adata_dict[sample_name] = humanized_adata\n",
    "\n",
    "# Save ortholog table\n",
    "df_ortholog.to_csv(\"mouse_human_orthologs.csv\", index=False)\n",
    "\n",
    "# Summary\n",
    "print(f\"âœ… Processed {len(filtered_adata_dict)} samples.\")\n",
    "print(f\"ðŸ§¬ Saved {df_ortholog.shape[0]} unique mouse-human orthologs to 'mouse_human_orthologs.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_adata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanorama\n",
    "\n",
    "# Make a list of the datasets\n",
    "datas = list(filtered_adata_dict.values())\n",
    "\n",
    "# Perform Scanorama integration\n",
    "integrated_data = scanorama.integrate_scanpy(datas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_adata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Concatenate all mouse datasets\n",
    "integrated_mouse_adata = sc.concat(datas, join='inner', label='Sample', keys=filtered_adata_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_mouse_adata\n",
    "integrated_mouse_adata.var_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as h5ad\n",
    "integrated_mouse_adata.write(\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Microglia_analysis/integrated_mouseMG_data.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
