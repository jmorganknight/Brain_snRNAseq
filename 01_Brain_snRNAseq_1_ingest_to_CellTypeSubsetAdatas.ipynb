{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lynn's Brain snRNAseq Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Lynn took fixed brains from mice infected with Candida albicans or left untreated, and had nucli isolated for snRNAseq.\n",
    "\n",
    "path for files: /media/jmk/drive_a/Project_Brain_snRNAseq\n",
    "snRNAseq 10x configuration: /media/jmk/drive_a/Project_Brain_snRNAseq/config.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a df of the samples and the path to their filtered matrix.h5 files \n",
    "# Define the root directory where your sample folders are located\n",
    "root_dir = \"/media/drive_c/Project_Brain_snRNAseq/per_sample_outs\"\n",
    "\n",
    "# Initialize an empty list to store sample names and file paths\n",
    "data = []\n",
    "\n",
    "# Loop through each subfolder in the root directory\n",
    "for sample_folder in os.listdir(root_dir):\n",
    "    sample_path = os.path.join(root_dir, sample_folder, 'count', 'sample_filtered_feature_bc_matrix.h5')\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(sample_path):\n",
    "        # Append sample name and file path to the list\n",
    "        data.append({'Sample': sample_folder, 'Path': sample_path})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('sample_paths.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing andata for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for doublet detection and filtering cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pp(h5_path, sample):\n",
    "    # Read the h5 file\n",
    "    adata = sc.read_10x_h5(h5_path, genome=None, gex_only=True)\n",
    "    # Make variables unique\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    # Filter genes\n",
    "    sc.pp.filter_genes(adata, min_cells=10)\n",
    "    # Filter for HVGs\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=2000, subset=True, flavor='seurat_v3')\n",
    "\n",
    "\n",
    "    # Doublet detection with scvi model\n",
    "    ## training the scvi model\n",
    "    scvi._settings.ScviConfig(dl_num_workers=60)\n",
    "    scvi.model.SCVI.setup_anndata(adata)\n",
    "    vae = scvi.model.SCVI(adata)\n",
    "    vae.train()\n",
    "\n",
    "    # Train the solo model\n",
    "    solo = scvi.external.SOLO.from_scvi_model(vae)\n",
    "    solo.train()\n",
    "\n",
    "    # df for doublet prediction\n",
    "    dfp = solo.predict()\n",
    "    dfp['prediction'] = solo.predict(soft = False)\n",
    "    dfp['dif'] = dfp.doublet - dfp.singlet\n",
    "    sns.displot(dfp[dfp.prediction == 'doublet'], x = 'dif')\n",
    "    # Save the plot as a PDF file\n",
    "    plt.savefig(\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Injest/{}_doubletPlot.pdf\".format(sample))\n",
    "\n",
    "    # Re-reading the h5 file\n",
    "    adata = sc.read_10x_h5(h5_path, genome=None, gex_only=True)\n",
    "    # Make variables unique\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    # Remove the predicted doublets\n",
    "    adata = adata[~adata.obs.index.isin(dfp.index[dfp['prediction'] == 'doublet'])]\n",
    "\n",
    "\n",
    "    # Add sample_id to adata.obs\n",
    "    adata.obs['Sample'] = sample\n",
    "\n",
    "    # Comiting raw data to .raw and a 'counts' layer\n",
    "    adata.layers[\"counts\"] = adata.X\n",
    "    \n",
    "  \n",
    "    # Filter cells on gene counts and cells\n",
    "    sc.pp.filter_cells(adata, min_genes=200)\n",
    "    sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "    upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98)\n",
    "    adata = adata[adata.obs.n_genes_by_counts < upper_lim]\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "    \n",
    "    # Calculate filter mitochondrial QC metrics\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('mt')\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    adata = adata[adata.obs.pct_counts_mt < 5]\n",
    "\n",
    "       \n",
    "    # Normalize, log-transform, comiting normalized data to a layer, Identify highly variable genes\n",
    "    sc.pp.normalize_total(adata, inplace=True, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.layers['log_norm'] = adata.X.copy()\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=2000, subset=True, flavor='seurat_v3')\n",
    "\n",
    "    adata.raw = adata\n",
    "        \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store AnnaData objects\n",
    "datas = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, Filter, Concat, and Var/groups addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the file path and sample ID from the current row\n",
    "    h5_path = row['Path']\n",
    "    sample_id = row['Sample']\n",
    "    print(f\"Processing row {index}: h5_path='{h5_path}', sample_id='{sample_id}'\")\n",
    "    \n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run the preprocessing function on the current sample\n",
    "    adata = pp(h5_path, sample_id)\n",
    "    \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # Print the elapsed time\n",
    "    print(f\"Processing time for row {index}: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Append the preprocessed AnnData object to the list\n",
    "    datas.append(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of AnnData objects into a single AnnData object\n",
    "adata = sc.concat(datas, join ='outer', uns_merge = 'same')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "### SKIP THIS AFTER INITIAL ANALYSIS ###\n",
    "\n",
    "# Adding back the var that were lost during concatenation\n",
    "# grab all var DataFrames from our dictionary\n",
    "all_var = [x.var for x in datas]\n",
    "# concatenate them\n",
    "all_var = pd.concat(all_var, join=\"outer\")\n",
    "# remove duplicates\n",
    "all_var = all_var[~all_var.index.duplicated()]\n",
    "# add var to adata\n",
    "adata.var = all_var.loc[adata.var_names]\n",
    "\n",
    "'''\n",
    "# Note: 'gene_ids', 'feature_types', 'genome', 'n_cells_by_counts', 'mean_counts', /\n",
    "#       'pct_dropout_by_counts', 'total_counts', 'n_cells', 'mt', 'highly_variable', /\n",
    "#       'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
    "\n",
    "# Define which columns you want to keep\n",
    "keep_cols = [\"gene_ids\"]\n",
    "\n",
    "# Grab .var from each dataset in the list and subset to columns we want (if they exist)\n",
    "all_var = [\n",
    "    x.var.loc[:, [c for c in keep_cols if c in x.var.columns]]\n",
    "    for x in datas\n",
    "]\n",
    "\n",
    "# Concatenate and drop duplicate gene names\n",
    "all_var = pd.concat(all_var, join=\"outer\")\n",
    "all_var = all_var[~all_var.index.duplicated()]\n",
    "\n",
    "# Subset to adata genes\n",
    "adata.var = all_var.loc[adata.var_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a treatment group obs for downstream analysis\n",
    "\n",
    "# Define sample groups\n",
    "naive_samples = ['Mock-1', 'Mock-2', 'Mock-3']\n",
    "infected_samples = ['OG-1', 'OG-2', 'OG-3']\n",
    "\n",
    "# Create a new column 'treatment' in adata.obs\n",
    "adata.obs['treatment'] = adata.obs['Sample'].apply(\n",
    "    lambda x: 'Naive' if x in naive_samples else ('Infected' if x in infected_samples else 'Unknown')\n",
    ")\n",
    "\n",
    "# Convert 'treatment' column to categorical type\n",
    "adata.obs['treatment'] = adata.obs['treatment'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Samples with Scanorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanorama\n",
    "\n",
    "scanorama.integrate_scanpy(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the integrated matrices\n",
    "scanorama_int = [ad.obsm['X_scanorama'] for ad in datas]\n",
    "\n",
    "# make into one matrix\n",
    "adata.obsm[\"Scanorama\"] = np.concatenate(scanorama_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Load Point:       Brain_snRNAseq_adata_injest.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the adata.X as the raw counts (layers 'counts')\n",
    "adata.X = adata.layers['counts']\n",
    "adata.write_h5ad('/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_adata_injest.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "\n",
    "# Reading in the adata from h5ad\n",
    "adata = ad.read_h5ad('/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_adata_injest.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapMyCells\n",
    "\n",
    "Publication: A high-resolution transcriptomic and spatial atlas of cell types in the whole mouse brain (PMID: 38092916)\n",
    "Source: https://github.com/AllenInstitute/cell_type_mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the gene symbols and store them in a new column 'gene_symbol'\n",
    "adata.var['gene_symbol'] = adata.var.index\n",
    "\n",
    "# Set the index of 'adata.var' to the 'gene_ids' column\n",
    "adata.var.set_index('gene_ids', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewriting the h5ad file so gene_ids are the index and map my cells is happy\n",
    "adata.write_h5ad('/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_index.gene_ids.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_index.gene_ids.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to run cell type mapper..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Cells are mapped with the original whole mouse brain atlas taxonomy from using MapMyCells\n",
    "\n",
    "(https://portal.brain-map.org/atlases-and-data/bkp/mapmycells)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run this through terminal\n",
    "\n",
    "!python -m cell_type_mapper.cli.from_specified_markers \\\n",
    "--query_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_index.gene_ids.h5ad \\\n",
    "--extended_result_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.json \\\n",
    "--csv_result_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.csv \\\n",
    "--drop_level CCN20230722_SUPT \\\n",
    "--cloud_safe False \\\n",
    "--query_markers.serialized_lookup /home/jmk/cell_type_mapper/Taxonomies/WMB/mouse_markers_230821.json \\\n",
    "--precomputed_stats.path /home/jmk/cell_type_mapper/Taxonomies/WMB/precomputed_stats_ABC_revision_230821.h5 \\\n",
    "--type_assignment.normalization raw \\\n",
    "--type_assignment.n_processors 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Note: The following command is for mapping the cells without using the GPU\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=\"\" python -m cell_type_mapper.cli.from_specified_markers \\\n",
    "--query_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/Brain_snRNAseq_index.gene_ids.h5ad \\\n",
    "--extended_result_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.json \\\n",
    "--csv_result_path /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.csv \\\n",
    "--drop_level CCN20230722_SUPT \\\n",
    "--cloud_safe False \\\n",
    "--query_markers.serialized_lookup /home/jmk/cell_type_mapper/Taxonomies/WMB/mouse_markers_230821.json \\\n",
    "--precomputed_stats.path /home/jmk/cell_type_mapper/Taxonomies/WMB/precomputed_stats_ABC_revision_230821.h5 \\\n",
    "--type_assignment.normalization raw \\\n",
    "--type_assignment.n_processors 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_results = pd.read_csv(\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.csv\", comment='#')\n",
    "csv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(csv_results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Cell Type Mapping to AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results into the AnnData object's obs\n",
    "adata.obs = adata.obs.merge(csv_results, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Verify the merge\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json file:  taxonomy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_path = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Mapping/mapping_output.json\"\n",
    "\n",
    "print(f\"=======READING {json_path}=======\")\n",
    "with open(json_path, 'r') as src:  # use 'r' for text mode with json.load\n",
    "    json_results = json.load(src)\n",
    "\n",
    "print(json_results.keys())  # should show keys like 'taxonomy_tree', etc.\n",
    "\n",
    "taxonomy_tree = json_results['taxonomy_tree']\n",
    "print(taxonomy_tree.keys())  # to confirm what levels/nodes are inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cell type mapping into a dict keyed on each cell's barcode\n",
    "mapping_result = {c['cell_id']: c for c in json_results['results']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celltype UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the function\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# The function to plot UMAP embeddings\n",
    "def plot_embedding(\n",
    "        barcode_to_label,\n",
    "        label_order,\n",
    "        fontsize=15,\n",
    "        raw_data=None,\n",
    "        save_path=None,\n",
    "        filtered_adata=None,  # ➡️ Name for the saved .h5ad file\n",
    "        palette_name='tab10'):\n",
    "    \"\"\"\n",
    "    Generate and plot a UMAP embedding of the raw data using Scanpy, \n",
    "    and optionally save the plot and filtered AnnData object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    barcode_to_label:\n",
    "        A dict mapping cell barcodes to labels (only includes\n",
    "        cells that we want included in the embedding).\n",
    "    label_order:\n",
    "        Order in which we want labels to appear on the color map.\n",
    "    fontsize:\n",
    "        Size of font to be used in the legend.\n",
    "    raw_data:\n",
    "        The AnnData object containing the raw data (cells, genes, and .X['counts']).\n",
    "    save_path:\n",
    "        The path where the plot will be saved. If None, the plot is not saved.\n",
    "    filtered_adata:\n",
    "        Name for the saved filtered AnnData object (.h5ad).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The path to the saved filtered AnnData object.\n",
    "    \"\"\"\n",
    "    if raw_data is None:\n",
    "        raise ValueError(\"raw_data must be provided as an AnnData object.\")\n",
    "\n",
    "    if filtered_adata is None:\n",
    "        raise ValueError(\"You must provide a name for the filtered AnnData object.\")\n",
    "\n",
    "    # Creating a mask to filter out only the cells with barcodes in barcode_to_label\n",
    "    barcodes = raw_data.obs.index.values\n",
    "    filter_mask = np.array([b in barcode_to_label for b in barcodes])\n",
    "\n",
    "    # Filter the AnnData object to include only the cells of interest\n",
    "    filtered_adata_obj = raw_data[filter_mask, :].copy()\n",
    "\n",
    "    # Add the labels to the AnnData object (used for coloring the UMAP plot)\n",
    "    labels = np.array([barcode_to_label[barcode] for barcode in filtered_adata_obj.obs.index])\n",
    "    filtered_adata_obj.obs['labels'] = labels\n",
    "\n",
    "    # Use Scanpy's UMAP function to compute UMAP\n",
    "    sc.pp.neighbors(filtered_adata_obj, n_pcs=50, n_neighbors=100, use_rep=\"Scanorama\")\n",
    "    sc.tl.umap(filtered_adata_obj, min_dist=1, spread=.8)\n",
    "\n",
    "    # Rotate UMAP coordinates by -90 degrees (clockwise)\n",
    "    umap_coords = filtered_adata_obj.obsm['X_umap']\n",
    "    rotated_umap_coords = np.zeros_like(umap_coords)\n",
    "    rotated_umap_coords[:, 0] = -umap_coords[:, 1]  # New x = -old y\n",
    "    rotated_umap_coords[:, 1] = umap_coords[:, 0]   # New y = old x\n",
    "    filtered_adata_obj.obsm['X_umap'] = rotated_umap_coords\n",
    "\n",
    "    # Handle color palette\n",
    "    if isinstance(palette_name, str):\n",
    "        palette = sns.color_palette(palette_name, n_colors=len(label_order))\n",
    "    elif isinstance(palette_name, list):\n",
    "        palette = palette_name\n",
    "    else:\n",
    "        raise ValueError(\"palette_name must be a string or a list of colors.\")\n",
    "\n",
    "    # Plot the UMAP\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sc.pl.umap(\n",
    "        filtered_adata_obj,\n",
    "        color='labels',\n",
    "        legend_loc='right margin',\n",
    "        title=\"Cell Class\",\n",
    "        legend_fontsize=fontsize,\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "    # Save the plot if save_path is provided\n",
    "    if save_path:\n",
    "        svg_path = Path(save_path).with_suffix(\".svg\")\n",
    "        fig.savefig(svg_path, dpi=300, bbox_inches='tight', format='svg')\n",
    "\n",
    "    \n",
    "    filtered_adata_obj.obs.index = filtered_adata_obj.obs.index.map(str)\n",
    "    for col in filtered_adata_obj.obs.columns:\n",
    "        filtered_adata_obj.obs[col] = filtered_adata_obj.obs[col].astype(str)\n",
    "\n",
    "    # Save the filtered AnnData object as an .h5ad file\n",
    "    adata_save_path = f\"{filtered_adata}.h5ad\"\n",
    "    filtered_adata_obj.write(adata_save_path)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    return adata_save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General categorization of cell types for plotting\n",
    "\n",
    "level = 'CCN20230722_CLAS'\n",
    "corr_cut = 0.4\n",
    "\n",
    "node_to_label = dict()\n",
    "for node in taxonomy_tree[level]:\n",
    "    name = taxonomy_tree['name_mapper'][level][node]['name']\n",
    "    if 'Glut' in name:\n",
    "        label = 'Glut'\n",
    "    elif 'GABA' in name:\n",
    "        label = 'GABA'\n",
    "    elif 'Dopa' in name:\n",
    "        label = 'Dopa'\n",
    "    elif 'Sero' in name:\n",
    "        label = 'Sero'\n",
    "    elif 'Astro' in name:\n",
    "        label = 'Astro'\n",
    "    elif 'OPC' in name:\n",
    "        label = 'OPC'\n",
    "    elif 'OEC' in name:\n",
    "        label = 'OEC'\n",
    "    elif 'Vascular' in name:\n",
    "        label = 'Vascular'\n",
    "    elif 'Immune' in name:\n",
    "        label = 'Immune'\n",
    "    else:\n",
    "        label = name\n",
    "    node_to_label[node] = label\n",
    "\n",
    "barcode_to_label = dict()\n",
    "for barcode in mapping_result:\n",
    "    cell = mapping_result[barcode]\n",
    "    if cell[level]['avg_correlation'] < corr_cut:\n",
    "        continue\n",
    "    barcode_to_label[barcode] = node_to_label[cell[level]['assignment']]\n",
    "\n",
    "label_order = ['Glut', 'GABA', 'Dopa', 'Sero', 'Astro', 'OPC', 'OEC', 'Vascular', 'Immune']\n",
    "for label in set(barcode_to_label.values()):\n",
    "    if label not in label_order:\n",
    "        label_order.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cell classes\n",
    "\n",
    "%%time\n",
    "plot_embedding(barcode_to_label=barcode_to_label, save_path='/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/UMAP/UMAP_Cell_Class', filtered_adata=\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/adata_filtered\", label_order=label_order, raw_data=adata, palette_name='tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celltype UMAP Count Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(f\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/adata_filtered.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# ========= i/o =========\n",
    "adata_path = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/adata_filtered.h5ad\"\n",
    "save_path  = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/UMAP/UMAP_Cell_Class_counts.svg\"  \n",
    "# =================================\n",
    "\n",
    "# Load AnnData\n",
    "adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "# Extract needed columns\n",
    "df = adata.obs[['labels', 'Sample']].copy()\n",
    "\n",
    "# Create group column (Mock or OG)\n",
    "df['group'] = df['Sample'].apply(lambda x: 'Mock' if 'Mock' in x else 'OG')\n",
    "\n",
    "# Count cells per label per sample\n",
    "count_df = (\n",
    "    df.groupby(['Sample', 'labels'])\n",
    "      .size()\n",
    "      .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Pivot so samples are rows, labels are columns\n",
    "label_count_matrix = count_df.pivot_table(\n",
    "    index='Sample',\n",
    "    columns='labels',\n",
    "    values='count',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Add group column\n",
    "label_count_matrix['group'] = label_count_matrix['Sample'].apply(\n",
    "    lambda x: 'Mock' if 'Mock' in x else 'OG'\n",
    ")\n",
    "\n",
    "# Melt for seaborn\n",
    "long_df = label_count_matrix.melt(\n",
    "    id_vars=['Sample', 'group'],\n",
    "    var_name='label',\n",
    "    value_name='count'\n",
    ")\n",
    "\n",
    "# Compute t-tests per label\n",
    "stats_results = []\n",
    "for label in long_df['label'].unique():\n",
    "    sub = long_df[long_df['label'] == label]\n",
    "    mock_vals = sub[sub['group'] == 'Mock']['count']\n",
    "    og_vals = sub[sub['group'] == 'OG']['count']\n",
    "    t_stat, p_val = ttest_ind(mock_vals, og_vals, equal_var=False)\n",
    "    stats_results.append({'label': label, 'p_value': p_val})\n",
    "\n",
    "stats_df = pd.DataFrame(stats_results)\n",
    "print(stats_df.sort_values('p_value'))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=long_df,\n",
    "    x='label',\n",
    "    y='count',\n",
    "    hue='group',\n",
    "    errorbar='se',\n",
    "    capsize=0.1,\n",
    "    errwidth=1.5,\n",
    "    palette='Set2'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=long_df,\n",
    "    x='label',\n",
    "    y='count',\n",
    "    hue='group',\n",
    "    dodge=True,\n",
    "    color='black',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Remove duplicate legend entries\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles[:2], labels[:2], title=\"Group\")\n",
    "\n",
    "plt.ylabel(\"Cell Count\")\n",
    "plt.xlabel(\"Cell Type\")\n",
    "plt.title(\"Cell Counts per Type (Mock vs OG) ± SEM\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as SVG\n",
    "plt.savefig(save_path, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Immune Cells for Subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Immune cells\n",
    "immune_cells = adata[adata.obs[\"labels\"].str.contains(\"Immune\")]\n",
    "\n",
    "# Get unique cluster_name values from those cells\n",
    "immune_clusters = immune_cells.obs[\"cluster_name\"].unique().tolist()\n",
    "\n",
    "print(immune_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# ========= i/o =========\n",
    "adata_path = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/adatas/adata_filtered.h5ad\"\n",
    "save_path  = \"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/UMAP/UMAP_Immune_Cluster_counts.svg\"  \n",
    "# =================================\n",
    "\n",
    "# Load AnnData\n",
    "adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "# ===== Subset to Immune cells =====\n",
    "immune_cells = adata[adata.obs['labels'] == 'Immune'].copy()\n",
    "\n",
    "# Extract needed columns\n",
    "df = immune_cells.obs[['cluster_name', 'Sample']].copy()\n",
    "\n",
    "# Create group column (Mock or OG)\n",
    "df['group'] = df['Sample'].apply(lambda x: 'Mock' if 'Mock' in x else 'OG')\n",
    "\n",
    "# Count cells per cluster_name per sample\n",
    "count_df = (\n",
    "    df.groupby(['Sample', 'cluster_name'])\n",
    "      .size()\n",
    "      .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Pivot so samples are rows, cluster_names are columns\n",
    "cluster_count_matrix = count_df.pivot_table(\n",
    "    index='Sample',\n",
    "    columns='cluster_name',\n",
    "    values='count',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Add group column\n",
    "cluster_count_matrix['group'] = cluster_count_matrix['Sample'].apply(\n",
    "    lambda x: 'Mock' if 'Mock' in x else 'OG'\n",
    ")\n",
    "\n",
    "# Melt for seaborn\n",
    "long_df = cluster_count_matrix.melt(\n",
    "    id_vars=['Sample', 'group'],\n",
    "    var_name='cluster_name',\n",
    "    value_name='count'\n",
    ")\n",
    "\n",
    "# Compute t-tests per cluster_name\n",
    "stats_results = []\n",
    "for cname in long_df['cluster_name'].unique():\n",
    "    sub = long_df[long_df['cluster_name'] == cname]\n",
    "    mock_vals = sub[sub['group'] == 'Mock']['count']\n",
    "    og_vals = sub[sub['group'] == 'OG']['count']\n",
    "    t_stat, p_val = ttest_ind(mock_vals, og_vals, equal_var=False)\n",
    "    stats_results.append({'cluster_name': cname, 'p_value': p_val})\n",
    "\n",
    "stats_df = pd.DataFrame(stats_results)\n",
    "print(stats_df.sort_values('p_value'))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=long_df,\n",
    "    x='cluster_name',\n",
    "    y='count',\n",
    "    hue='group',\n",
    "    errorbar='se',\n",
    "    capsize=0.1,\n",
    "    errwidth=1.5,\n",
    "    palette='Set2'\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=long_df,\n",
    "    x='cluster_name',\n",
    "    y='count',\n",
    "    hue='group',\n",
    "    dodge=True,\n",
    "    color='black',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Remove duplicate legend entries\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles[:2], labels[:2], title=\"Group\")\n",
    "\n",
    "plt.ylabel(\"Cell Count\")\n",
    "plt.xlabel(\"Immune Cluster Name\")\n",
    "plt.title(\"Immune Cluster Counts per Sample (Mock vs OG) ± SEM\")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as SVG\n",
    "plt.savefig(save_path, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Cell Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microgila barcodes\n",
    "\n",
    "\n",
    "Path to: /media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Microglia_analysis/\n",
    "\n",
    "Note: Exported for Microglia mouse to human comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Subset to Microglia cells based on cluster_name\n",
    "microglia_cells = adata[adata.obs['cluster_name'].str.contains('Microglia', case=False, na=False)].copy()\n",
    "\n",
    "# 2. Extract cell barcodes (index) into a DataFrame\n",
    "barcode_df = pd.DataFrame(microglia_cells.obs.index, columns=['cell_barcode'])\n",
    "\n",
    "# 3. Save to CSV\n",
    "barcode_df.to_csv(\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Microglia_analysis/microglia_cell_barcodes.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astrocyte Barcodes\n",
    "\n",
    "Note: Exported for Path Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Subset to Astrocyte cells based on cluster_name\n",
    "astro_cells = adata[adata.obs['cluster_name'].str.contains('astro', case=False, na=False)].copy()\n",
    "\n",
    "# 2. Extract cell barcodes (index) into a DataFrame\n",
    "barcode_df = pd.DataFrame(astro_cells.obs.index, columns=['cell_barcode'])\n",
    "\n",
    "# 3. Save to CSV\n",
    "barcode_df.to_csv(\"/media/drive_c/Project_Brain_snRNAseq/Analysis/Results/Astrocyte_analysis/astrocyte_cell_barcodes.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
